"""
stats_tracker.py
----------------
Accumulates per-layer and per-component RMSE statistics across inference calls.

Design:
- Each QuantLinear calls tracker.record() after every forward pass.
- StatsTracker accumulates running mean-squared error (numerically stable via
  Welford's online algorithm) so we can average across many inference steps
  without storing all outputs.
- At the end of evaluation, call tracker.summary() to get a dict with:
    - Per-layer stats (name, component, rmse, n_calls, tensor_elements)
    - Per-component aggregate stats (mean RMSE and std across layers)
  These can be trivially converted to a DataFrame for analysis.

Component taxonomy (matching Pi0's architecture):
    VISION         — SigLIP ViT encoder layers
    LANGUAGE       — PaliGemma Gemma language model layers
    ACTION_EXPERT  — Gemma action-expert transformer layers
    ACTION_HEAD    — Thin action projection MLPs at the Pi0 level
"""

from __future__ import annotations

import math
from collections import defaultdict
from dataclasses import dataclass, field
from enum import Enum
from typing import Dict, List, Optional

import torch


# ---------------------------------------------------------------------------
# Component taxonomy
# ---------------------------------------------------------------------------

class Component(str, Enum):
    VISION        = "vision"
    LANGUAGE      = "language"
    ACTION_EXPERT = "action_expert"
    ACTION_HEAD   = "action_head"
    UNKNOWN       = "unknown"


# ---------------------------------------------------------------------------
# Per-layer running statistics (Welford's online algorithm)
# ---------------------------------------------------------------------------

@dataclass
class LayerStats:
    """Welford online mean of squared-error per layer."""
    name: str
    component: Component
    in_features: int
    out_features: int

    # Internal Welford accumulators
    _n: int   = field(default=0, repr=False)
    _mean_mse: float = field(default=0.0, repr=False)
    _M2: float = field(default=0.0, repr=False)  # for variance across calls

    def update(self, y_fp: torch.Tensor, y_quant: torch.Tensor) -> None:
        """
        Update running stats with one forward-pass batch.

        We compute MSE over the full output tensor (all batch elements, all
        sequence positions, all output features), then treat that scalar as
        one new observation for Welford's running mean/variance.
        """
        with torch.no_grad():
            diff = y_fp.float() - y_quant.float()
            mse = diff.pow(2).mean().item()

        # Welford's online update
        self._n += 1
        delta = mse - self._mean_mse
        self._mean_mse += delta / self._n
        delta2 = mse - self._mean_mse
        self._M2 += delta * delta2

    @property
    def n_calls(self) -> int:
        return self._n

    @property
    def rmse(self) -> float:
        """Root mean squared error averaged over all observed calls."""
        if self._n == 0:
            return float("nan")
        return math.sqrt(max(self._mean_mse, 0.0))

    @property
    def mse(self) -> float:
        if self._n == 0:
            return float("nan")
        return self._mean_mse

    @property
    def mse_std(self) -> float:
        """Std of per-call MSE values (Welford variance)."""
        if self._n < 2:
            return float("nan")
        return math.sqrt(self._M2 / (self._n - 1))

    def to_dict(self) -> dict:
        return {
            "layer":        self.name,
            "component":    self.component.value,
            "in_features":  self.in_features,
            "out_features": self.out_features,
            "n_calls":      self._n,
            "rmse":         self.rmse,
            "mse":          self.mse,
            "mse_std":      self.mse_std,
        }


# ---------------------------------------------------------------------------
# Per-component aggregate
# ---------------------------------------------------------------------------

@dataclass
class ComponentStats:
    component: Component
    n_layers: int
    mean_rmse: float   # mean of per-layer RMSE values
    std_rmse: float    # std of per-layer RMSE values
    max_rmse: float
    min_rmse: float
    total_calls: int   # sum of n_calls across all layers in this component

    def to_dict(self) -> dict:
        return {
            "component":   self.component.value,
            "n_layers":    self.n_layers,
            "mean_rmse":   self.mean_rmse,
            "std_rmse":    self.std_rmse,
            "max_rmse":    self.max_rmse,
            "min_rmse":    self.min_rmse,
            "total_calls": self.total_calls,
        }


# ---------------------------------------------------------------------------
# Main tracker
# ---------------------------------------------------------------------------

class StatsTracker:
    """
    Central store for quantization RMSE statistics across all QuantLinear layers.

    Usage:
        tracker = StatsTracker()
        # Pass to model_patcher.patch_model(..., tracker=tracker)
        # Run inference (possibly many steps)
        report = tracker.summary()
        report.print()
        df = report.to_dataframe()   # requires pandas
    """

    def __init__(self) -> None:
        self._layers: Dict[str, LayerStats] = {}

    def register(
        self,
        name: str,
        component: Component,
        in_features: int,
        out_features: int,
    ) -> None:
        """Called by model_patcher when building QuantLinear layers."""
        if name not in self._layers:
            self._layers[name] = LayerStats(
                name=name,
                component=component,
                in_features=in_features,
                out_features=out_features,
            )

    def record(
        self,
        name: str,
        component: Component,
        y_fp: torch.Tensor,
        y_quant: torch.Tensor,
    ) -> None:
        """Called by QuantLinear.forward() after each matmul."""
        if name not in self._layers:
            # Auto-register if not pre-registered
            self._layers[name] = LayerStats(
                name=name,
                component=component,
                in_features=y_quant.shape[-1],
                out_features=y_quant.shape[-1],
            )
        self._layers[name].update(y_fp, y_quant)

    def reset(self) -> None:
        """Reset all accumulated statistics (e.g., between evaluation episodes)."""
        for stats in self._layers.values():
            stats._n = 0
            stats._mean_mse = 0.0
            stats._M2 = 0.0

    def layer_rows(self) -> List[dict]:
        """Return a list of dicts (one per layer), sorted by component then name."""
        return [
            s.to_dict()
            for s in sorted(self._layers.values(), key=lambda s: (s.component.value, s.name))
        ]

    def component_rows(self) -> List[dict]:
        """Return per-component aggregate stats."""
        by_component: Dict[Component, List[LayerStats]] = defaultdict(list)
        for s in self._layers.values():
            by_component[s.component].append(s)

        rows = []
        for comp in Component:
            layers = by_component.get(comp, [])
            if not layers:
                continue
            rmse_values = [s.rmse for s in layers if not math.isnan(s.rmse)]
            if not rmse_values:
                continue
            rows.append(ComponentStats(
                component=comp,
                n_layers=len(layers),
                mean_rmse=_safe_mean(rmse_values),
                std_rmse=_safe_std(rmse_values),
                max_rmse=max(rmse_values),
                min_rmse=min(rmse_values),
                total_calls=sum(s.n_calls for s in layers),
            ).to_dict())
        return rows

    def summary(self) -> "StatsReport":
        return StatsReport(
            layer_rows=self.layer_rows(),
            component_rows=self.component_rows(),
        )


# ---------------------------------------------------------------------------
# Report object
# ---------------------------------------------------------------------------

@dataclass
class StatsReport:
    layer_rows: List[dict]
    component_rows: List[dict]

    def print(self, show_layers: bool = False) -> None:
        """Pretty-print to stdout."""
        print("\n=== Per-Component RMSE ===")
        _print_table(self.component_rows, [
            ("component", 14),
            ("n_layers",  8),
            ("mean_rmse", 12),
            ("std_rmse",  12),
            ("max_rmse",  12),
            ("min_rmse",  12),
            ("total_calls", 12),
        ])

        if show_layers:
            print("\n=== Per-Layer RMSE ===")
            _print_table(self.layer_rows, [
                ("component",   14),
                ("layer",       60),
                ("n_calls",      8),
                ("rmse",        12),
                ("mse_std",     12),
            ])

    def to_dataframe(self):
        """Convert to pandas DataFrames. Requires pandas."""
        try:
            import pandas as pd
        except ImportError:
            raise ImportError("pip install pandas to use to_dataframe()")
        return (
            pd.DataFrame(self.layer_rows),
            pd.DataFrame(self.component_rows),
        )

    def to_dict(self) -> dict:
        return {
            "layers":     self.layer_rows,
            "components": self.component_rows,
        }


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _safe_mean(values: list[float]) -> float:
    return sum(values) / len(values) if values else float("nan")

def _safe_std(values: list[float]) -> float:
    if len(values) < 2:
        return 0.0
    m = _safe_mean(values)
    return math.sqrt(sum((v - m) ** 2 for v in values) / (len(values) - 1))

def _fmt(v, width: int) -> str:
    if isinstance(v, float):
        return f"{v:.4e}".ljust(width)
    return str(v).ljust(width)

def _print_table(rows: list[dict], cols: list[tuple[str, int]]) -> None:
    header = "  ".join(name.ljust(w) for name, w in cols)
    sep    = "  ".join("-" * w for _, w in cols)
    print(header)
    print(sep)
    for row in rows:
        line = "  ".join(_fmt(row.get(name, ""), w) for name, w in cols)
        print(line)
